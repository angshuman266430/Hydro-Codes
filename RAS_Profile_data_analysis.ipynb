{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd08a84",
   "metadata": {},
   "source": [
    "# RAS Profile Data Analysis\n",
    "\n",
    "This notebook outlines a process for analyzing hydrological data stored in HDF5 format. \n",
    "It demonstrates how to:\n",
    "- Generate a series of dates for a given period.\n",
    "- Extract specific datasets from HDF5 files.\n",
    "- Process and plot the extracted data for visualization.\n",
    "\n",
    "The analysis focuses on two types of data: Water Surface and Flow rates at different reference lines within the study area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798078a",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "First, we import the necessary libraries for handling HDF5 files, numerical operations, and data visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd7742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12109f4",
   "metadata": {},
   "source": [
    "## Helper Functions for ARI Events\n",
    "\n",
    "Several functions are defined to streamline the process of data extraction, processing, and visualization:\n",
    "\n",
    "- `generate_dates`: Generates a list of datetime objects between two specified dates.\n",
    "- `extract_names`: Extracts the names of reference lines from an HDF5 file.\n",
    "- `extract_time_series`: Extracts time series data for Water Surface or Flow from an HDF5 file.\n",
    "- `process_data`: Processes the extracted data for plotting.\n",
    "- `plot_profile_time_series`: Creates and saves a plot of the time series data for a given reference line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caaee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(start_date, end_date, num_steps):\n",
    "    start = datetime.strptime(start_date, \"%d %b %Y %H:%M\")\n",
    "    end = datetime.strptime(end_date, \"%d %b %Y %H:%M\")\n",
    "    delta = (end - start) / (num_steps - 1)\n",
    "    return [start + i * delta for i in range(num_steps)]\n",
    "\n",
    "\n",
    "def extract_names(hdf_file_path, data_type):\n",
    "    names_path = \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Name\"\n",
    "    with h5py.File(hdf_file_path, \"r\") as f:\n",
    "        names_data = f[names_path][()]\n",
    "        names = [name.split('|')[0] for name in names_data.astype(str)]\n",
    "        return names\n",
    "\n",
    "\n",
    "def extract_time_series(hdf_file_path, data_type):\n",
    "    data_paths = {\n",
    "        \"Water Surface\": \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Water Surface\",\n",
    "        \"Flow\": \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Flow\"\n",
    "    }\n",
    "    with h5py.File(hdf_file_path, \"r\") as f:\n",
    "        data_path = data_paths.get(data_type)\n",
    "        if data_path in f:\n",
    "            data = f[data_path][()]\n",
    "            data = np.nan_to_num(data)\n",
    "            return data\n",
    "        else:\n",
    "            raise KeyError(f\"Data path '{data_path}' not found in the HDF file.\")\n",
    "\n",
    "\n",
    "def process_data(data, data_type):\n",
    "    return data.T\n",
    "\n",
    "\n",
    "\n",
    "def plot_profile_time_series(data, names, data_type, output_folder, dates):\n",
    "    name_mapping = {\n",
    "        \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "        \"CryingBrewery\": \"Crying Brewery\",\n",
    "        \"GT\": \"Greinwich Terrace\",\n",
    "        \"Near_LegionSt\": \"Near Legion St\",\n",
    "        \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "    }\n",
    "\n",
    "    for idx, name in enumerate(names):\n",
    "        if name in name_mapping:\n",
    "            plt.figure(figsize=(10, 6), dpi=300)\n",
    "            ax = plt.gca()\n",
    "\n",
    "            data_to_plot = data[idx, :]\n",
    "\n",
    "            plt.plot(dates, data_to_plot, label=f'{name_mapping[name]}', color='navy', linewidth=2)\n",
    "\n",
    "            plot_title = f\"{name_mapping[name]}\"\n",
    "            plt.title(plot_title, fontsize=20)\n",
    "            plt.xlabel(\"Date\", fontsize=16)\n",
    "            plt.ylabel(f\"{data_type.replace('_', ' ').title()} ({'ftÂ³/s' if data_type == 'Flow' else 'ft'})\", fontsize=16)\n",
    "\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%d %b %Y %H:%M'))\n",
    "\n",
    "            # Increase font size of tick labels for both axes\n",
    "            ax.tick_params(axis='x', labelsize=14)\n",
    "            ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['left'].set_color('black')\n",
    "            ax.spines['left'].set_linewidth(2)\n",
    "            ax.spines['bottom'].set_color('black')\n",
    "            ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "            ax.set_facecolor('white')\n",
    "            ax.figure.set_facecolor('white')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            file_name = f\"{data_type}_{name.replace('_', '')}_time_series_profile.png\"\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "            plt.savefig(output_file_path, bbox_inches='tight', facecolor=ax.figure.get_facecolor())\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def main(hdf_file_base_path, output_base_folder, hdf_suffixes):\n",
    "    start_date = \"2 Jan 1970 00:00\"\n",
    "    end_date = \"9 Jan 1970 12:00\"\n",
    "\n",
    "\n",
    "    for suffix in hdf_suffixes:\n",
    "        hdf_file_path = f\"{hdf_file_base_path}{suffix}.hdf\"\n",
    "        output_folder = f\"{output_base_folder}_{suffix}\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for data_type in [\"Water Surface\", \"Flow\"]:\n",
    "            names = extract_names(hdf_file_path, data_type)\n",
    "            data = extract_time_series(hdf_file_path, data_type)\n",
    "            data_processed = process_data(data, data_type)\n",
    "            dates = generate_dates(start_date, end_date, data_processed.shape[1])\n",
    "            plot_profile_time_series(data_processed, names, data_type, output_folder, dates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf24bd",
   "metadata": {},
   "source": [
    "## Main Procedure\n",
    "\n",
    "The `main` function orchestrates the process of data extraction, processing, and visualization for each HDF5 file specified. \n",
    "It utilizes the helper functions to generate plots for each type of data (Water Surface and Flow) and saves them to the output directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef8516",
   "metadata": {},
   "source": [
    "## Plot all the ARI plans with single plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fdb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hdf_file_base_path = \"S:\\\\For_Angshuman\\\\Greenbelt\\\\Task_ProfilePlots_2_27_2024\\\\Greenbelt_RAS.p\"\n",
    "    output_base_folder = \"output_plots\"\n",
    "    hdf_suffixes = [\"01\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"16\", \"18\"]\n",
    "\n",
    "    main(hdf_file_base_path, output_base_folder, hdf_suffixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae58dc7",
   "metadata": {},
   "source": [
    "## Saving the ARI dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_data_to_csv(data_processed, names, data_type, output_folder, dates, suffix, name_mapping):\n",
    "    \"\"\"\n",
    "    Save the processed data into CSV files for each data type and suffix.\n",
    "\n",
    "    Args:\n",
    "    - data_processed (np.array): The processed data for all reference lines.\n",
    "    - names (list): List of reference line names before mapping.\n",
    "    - data_type (str): The type of data ('Flow' or 'Water Surface').\n",
    "    - output_folder (str): The base folder where CSV files will be saved.\n",
    "    - dates (list): List of datetime objects for each data point.\n",
    "    - suffix (str): The HDF file suffix, indicating the specific dataset.\n",
    "    - name_mapping (dict): A dictionary for mapping original names to desired names.\n",
    "    \"\"\"\n",
    "    for idx, original_name in enumerate(names):\n",
    "        if original_name in name_mapping:\n",
    "            # Map the original name to the desired name\n",
    "            friendly_name = name_mapping[original_name]\n",
    "            # Create a DataFrame from the processed data\n",
    "            df = pd.DataFrame(data_processed[idx, :], index=dates, columns=[friendly_name])\n",
    "            df.index.name = 'Date'\n",
    "            # Define the output CSV file path\n",
    "            output_csv_path = os.path.join(output_folder, f\"{suffix}_{data_type}_{friendly_name.replace(' ', '_')}.csv\")\n",
    "            # Save the DataFrame to CSV\n",
    "            df.to_csv(output_csv_path)\n",
    "\n",
    "def main(hdf_file_base_path, output_base_folder, hdf_suffixes):\n",
    "    start_date = \"2 Jan 1970 00:00\"\n",
    "    end_date = \"9 Jan 1970 12:00\"\n",
    "    name_mapping = {\n",
    "        \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "        \"CryingBrewery\": \"Crying Brewery\",\n",
    "        \"GT\": \"Greinwich Terrace\",\n",
    "        \"Near_LegionSt\": \"Near Legion St\",\n",
    "        \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "    }\n",
    "\n",
    "    for suffix in hdf_suffixes:\n",
    "        hdf_file_path = f\"{hdf_file_base_path}{suffix}.hdf\"\n",
    "        output_folder_suffix = f\"{output_base_folder}_{suffix}\"\n",
    "        \n",
    "        if not os.path.exists(output_folder_suffix):\n",
    "            os.makedirs(output_folder_suffix)\n",
    "\n",
    "        for data_type in [\"Water Surface\", \"Flow\"]:\n",
    "            names = extract_names(hdf_file_path, data_type)\n",
    "            data = extract_time_series(hdf_file_path, data_type)\n",
    "            data_processed = process_data(data, data_type)\n",
    "            dates = generate_dates(start_date, end_date, data_processed.shape[1])\n",
    "            \n",
    "            # Save the data into CSV files instead of plotting\n",
    "            save_data_to_csv(data_processed, names, data_type, output_folder_suffix, dates, suffix, name_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hdf_file_base_path = \"S:\\\\For_Angshuman\\\\Greenbelt\\\\Task_ProfilePlots_2_27_2024\\\\Greenbelt_RAS.p\"\n",
    "    output_base_folder = \"dataframes_output\"\n",
    "    hdf_suffixes = [\"01\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"16\", \"18\"]\n",
    "\n",
    "    if not os.path.exists(output_base_folder):\n",
    "        os.makedirs(output_base_folder)\n",
    "\n",
    "    main(hdf_file_base_path, output_base_folder, hdf_suffixes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b37a0",
   "metadata": {},
   "source": [
    "## Functions for couple plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d52c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def format_title_legend(scenario):\n",
    "    \"\"\"\n",
    "    Generate formatted title based on the scenario details.\n",
    "    \"\"\"\n",
    "    # Split the scenario details\n",
    "    parts = scenario.split('_')\n",
    "    A, B, C, D = parts[0], parts[1], parts[2], parts[3]\n",
    "    \n",
    "    # Mapping for the year and tide parts\n",
    "    year_tide_mapping = {\n",
    "        \"010yr\": \"10 year\", \"050yr\": \"50 year\", \"100yr\": \"100 year\",\n",
    "        \"MeanTide50%\": \"Mean Tide 50%\", \"HighTide50%\": \"High Tide 50%\"\n",
    "    }\n",
    "    \n",
    "    # Format title\n",
    "    year_formatted = year_tide_mapping.get(A, A)\n",
    "    tide_formatted = year_tide_mapping.get(D, D)\n",
    "    title = f\"{year_formatted}, {B}, {tide_formatted}\"\n",
    "    \n",
    "    return title\n",
    "\n",
    "def determine_legend(suffix):\n",
    "    \"\"\"\n",
    "    Determine legend label based on suffix.\n",
    "    \"\"\"\n",
    "    with_project_suffixes = ['03', '04', '08', '09', '10', '11']\n",
    "    return \"With Project\" if str(suffix).endswith(tuple(with_project_suffixes)) else \"Existing Conditions\"\n",
    "\n",
    "def plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping):\n",
    "    output_folder = \"plots\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for data_type in data_types:\n",
    "        for scenario in scenarios:\n",
    "            title = format_title_legend(scenario)\n",
    "            for name_key, friendly_name in name_mapping.items():\n",
    "                plt.figure(figsize=(10, 6), dpi=300)\n",
    "                ax = plt.gca()\n",
    "\n",
    "                legend_labels = set()\n",
    "                for suffix in suffixes:\n",
    "                    legend_label = determine_legend(suffix)\n",
    "                    if legend_label in legend_labels:\n",
    "                        continue\n",
    "                    legend_labels.add(legend_label)\n",
    "\n",
    "                    file_pattern = f\"{base_folder}_{suffix}/{suffix}_{data_type}_{friendly_name.replace(' ', '_')}.csv\"\n",
    "                    files = glob.glob(file_pattern)\n",
    "                    for file_path in files:\n",
    "                        df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "                        plt.plot(df.index, df.iloc[:, 0], label=legend_label, linewidth=2)\n",
    "\n",
    "                plt.title(f\"{friendly_name}: {title}\", fontsize=20)\n",
    "                plt.xlabel(\"Date\", fontsize=16)\n",
    "                plt.ylabel(f\"{data_type.replace('_', ' ').title()} ({'ftÂ³/s' if data_type == 'Flow' else 'ft'})\", fontsize=16)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d %b %Y'))\n",
    "\n",
    "                ax.tick_params(axis='x', labelsize=14)\n",
    "                ax.tick_params(axis='y', labelsize=14)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.spines['left'].set_color('black')\n",
    "                ax.spines['left'].set_linewidth(2)\n",
    "                ax.spines['bottom'].set_color('black')\n",
    "                ax.spines['bottom'].set_linewidth(2)\n",
    "                ax.set_facecolor('white')\n",
    "                ax.figure.set_facecolor('white')\n",
    "\n",
    "                plt.legend(fontsize=16)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                plot_filename = os.path.join(output_folder, f\"{data_type}_{friendly_name}_{title.replace(',', '').replace(' ', '_')}.png\")\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe78091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['01', '03']  # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"010yr_24hr_Without_MeanTide50%\",\n",
    "    \"010yr_24hr_WithProject_MeanTide50%\"\n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807d4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['05', '04']  # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"010yr_24hr_Without_HighTide50%\",\n",
    "    \"010yr_24hr_WithProject_HighTide50%\"\n",
    "    \n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15126ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['06', '09'] # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"050yr_24hr_Without_HighTide50%\",\n",
    "    \"050yr_24hr_WithProject_HighTide50%\"\n",
    "    \n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef6569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['07', '08'] # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"050yr_24hr_Without_MeanTide50%\",\n",
    "    \"050yr_24hr_WithProject_MeanTide50%\"\n",
    "    \n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad3ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['13', '10'] # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"100yr_24hr_Without_HighTide50%\",\n",
    "    \"100yr_24hr_WithProject_HighTide50%\"    \n",
    "    \n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320d7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "suffixes = ['12', '11'] # Include all relevant suffixes\n",
    "data_types = ['Flow', 'Water Surface']\n",
    "scenarios = [\n",
    "    \"100yr_24hr_Without_MeanTide50%\" ,\n",
    "    \"100yr_24hr_WithProject_MeanTide50%\"\n",
    "          \n",
    "]\n",
    "\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying Brewery\",\n",
    "    \"GT\": \"Greinwich Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "    \"Near_LegionSt\": \"Near Legion St\",\n",
    "    \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "}\n",
    "# Ensure the parameters for plotting are correctly defined as before\n",
    "\n",
    "plot_data_pairs(base_folder, suffixes, data_types, scenarios, name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635301b",
   "metadata": {},
   "source": [
    "## Helper Functions for May Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98b5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(start_date, end_date, num_steps):\n",
    "    start = datetime.strptime(start_date, \"%d %b %Y %H:%M\")\n",
    "    end = datetime.strptime(end_date, \"%d %b %Y %H:%M\")\n",
    "    delta = (end - start) / (num_steps - 1)\n",
    "    return [start + i * delta for i in range(num_steps)]\n",
    "\n",
    "\n",
    "def extract_names(hdf_file_path, data_type):\n",
    "    names_path = \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Name\"\n",
    "    with h5py.File(hdf_file_path, \"r\") as f:\n",
    "        names_data = f[names_path][()]\n",
    "        names = [name.split('|')[0] for name in names_data.astype(str)]\n",
    "        return names\n",
    "\n",
    "\n",
    "def extract_time_series(hdf_file_path, data_type):\n",
    "    data_paths = {\n",
    "        \"Water Surface\": \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Water Surface\",\n",
    "        \"Flow\": \"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines/Flow\"\n",
    "    }\n",
    "    with h5py.File(hdf_file_path, \"r\") as f:\n",
    "        data_path = data_paths.get(data_type)\n",
    "        if data_path in f:\n",
    "            data = f[data_path][()]\n",
    "            data = np.nan_to_num(data)\n",
    "            return data\n",
    "        else:\n",
    "            raise KeyError(f\"Data path '{data_path}' not found in the HDF file.\")\n",
    "\n",
    "\n",
    "def process_data(data, data_type):\n",
    "    return data.T\n",
    "\n",
    "\n",
    "\n",
    "def plot_profile_time_series(data, names, data_type, output_folder, dates):\n",
    "    name_mapping = {\n",
    "        \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "        \"CryingBrewery\": \"Crying Brewery\",\n",
    "        \"GT\": \"Greinwich Terrace\",\n",
    "        \"Near_LegionSt\": \"Near Legion St\",\n",
    "        \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "    }\n",
    "\n",
    "    for idx, name in enumerate(names):\n",
    "        if name in name_mapping:\n",
    "            plt.figure(figsize=(10, 6), dpi=300)\n",
    "            ax = plt.gca()\n",
    "\n",
    "            data_to_plot = data[idx, :]\n",
    "\n",
    "            plt.plot(dates, data_to_plot, label=f'{name_mapping[name]}', color='navy', linewidth=2)\n",
    "\n",
    "            plot_title = f\"{name_mapping[name]}\"\n",
    "            plt.title(plot_title, fontsize=20)\n",
    "            plt.xlabel(\"Date\", fontsize=16)\n",
    "            plt.ylabel(f\"{data_type.replace('_', ' ').title()} ({'ftÂ³/s' if data_type == 'Flow' else 'ft'})\", fontsize=16)\n",
    "\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%d %b %Y %H:%M'))\n",
    "\n",
    "            # Increase font size of tick labels for both axes\n",
    "            ax.tick_params(axis='x', labelsize=14)\n",
    "            ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['left'].set_color('black')\n",
    "            ax.spines['left'].set_linewidth(2)\n",
    "            ax.spines['bottom'].set_color('black')\n",
    "            ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "            ax.set_facecolor('white')\n",
    "            ax.figure.set_facecolor('white')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            file_name = f\"{data_type}_{name.replace('_', '')}_time_series_profile.png\"\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "            plt.savefig(output_file_path, bbox_inches='tight', facecolor=ax.figure.get_facecolor())\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def main(hdf_file_base_path, output_base_folder, hdf_suffixes):\n",
    "    start_date = \"16 May 2021 00:00\"\n",
    "    end_date = \"24 May 2021 12:00\"\n",
    "\n",
    "\n",
    "    for suffix in hdf_suffixes:\n",
    "        hdf_file_path = f\"{hdf_file_base_path}{suffix}.hdf\"\n",
    "        output_folder = f\"{output_base_folder}_{suffix}\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for data_type in [\"Water Surface\", \"Flow\"]:\n",
    "            names = extract_names(hdf_file_path, data_type)\n",
    "            data = extract_time_series(hdf_file_path, data_type)\n",
    "            data_processed = process_data(data, data_type)\n",
    "            dates = generate_dates(start_date, end_date, data_processed.shape[1])\n",
    "            plot_profile_time_series(data_processed, names, data_type, output_folder, dates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec2df5",
   "metadata": {},
   "source": [
    "## Plot all the May Events plans with single plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f2611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hdf_file_base_path = \"S:\\\\For_Angshuman\\\\Greenbelt\\\\Task_ProfilePlots_2_27_2024\\\\Greenbelt_RAS.p\"\n",
    "    output_base_folder = \"output_plots\"\n",
    "    hdf_suffixes = [\"02\", \"15\", \"17\"]\n",
    "\n",
    "    main(hdf_file_base_path, output_base_folder, hdf_suffixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034918f5",
   "metadata": {},
   "source": [
    "## Saving May Events Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985b4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_data_to_csv(data_processed, names, data_type, output_folder, dates, suffix, name_mapping):\n",
    "    \"\"\"\n",
    "    Save the processed data into CSV files for each data type and suffix.\n",
    "\n",
    "    Args:\n",
    "    - data_processed (np.array): The processed data for all reference lines.\n",
    "    - names (list): List of reference line names before mapping.\n",
    "    - data_type (str): The type of data ('Flow' or 'Water Surface').\n",
    "    - output_folder (str): The base folder where CSV files will be saved.\n",
    "    - dates (list): List of datetime objects for each data point.\n",
    "    - suffix (str): The HDF file suffix, indicating the specific dataset.\n",
    "    - name_mapping (dict): A dictionary for mapping original names to desired names.\n",
    "    \"\"\"\n",
    "    for idx, original_name in enumerate(names):\n",
    "        if original_name in name_mapping:\n",
    "            # Map the original name to the desired name\n",
    "            friendly_name = name_mapping[original_name]\n",
    "            # Create a DataFrame from the processed data\n",
    "            df = pd.DataFrame(data_processed[idx, :], index=dates, columns=[friendly_name])\n",
    "            df.index.name = 'Date'\n",
    "            # Define the output CSV file path\n",
    "            output_csv_path = os.path.join(output_folder, f\"{suffix}_{data_type}_{friendly_name.replace(' ', '_')}.csv\")\n",
    "            # Save the DataFrame to CSV\n",
    "            df.to_csv(output_csv_path)\n",
    "\n",
    "def main(hdf_file_base_path, output_base_folder, hdf_suffixes):\n",
    "    start_date = \"16 May 2021 00:00\"\n",
    "    end_date = \"24 May 2021 12:00\"\n",
    "    name_mapping = {\n",
    "        \"Kaouche_Coulee\": \"Kayouche Coulee\",\n",
    "        \"CryingBrewery\": \"Crying Brewery\",\n",
    "        \"GT\": \"Greinwich Terrace\",\n",
    "        \"Near_LegionSt\": \"Near Legion St\",\n",
    "        \"W_Sale_Rd\": \"West Sale Rd\"\n",
    "    }\n",
    "\n",
    "    for suffix in hdf_suffixes:\n",
    "        hdf_file_path = f\"{hdf_file_base_path}{suffix}.hdf\"\n",
    "        output_folder_suffix = f\"{output_base_folder}_{suffix}\"\n",
    "        \n",
    "        if not os.path.exists(output_folder_suffix):\n",
    "            os.makedirs(output_folder_suffix)\n",
    "\n",
    "        for data_type in [\"Water Surface\", \"Flow\"]:\n",
    "            names = extract_names(hdf_file_path, data_type)\n",
    "            data = extract_time_series(hdf_file_path, data_type)\n",
    "            data_processed = process_data(data, data_type)\n",
    "            dates = generate_dates(start_date, end_date, data_processed.shape[1])\n",
    "            \n",
    "            # Save the data into CSV files instead of plotting\n",
    "            save_data_to_csv(data_processed, names, data_type, output_folder_suffix, dates, suffix, name_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hdf_file_base_path = \"S:\\\\For_Angshuman\\\\Greenbelt\\\\Task_ProfilePlots_2_27_2024\\\\Greenbelt_RAS.p\"\n",
    "    output_base_folder = \"dataframes_output\"\n",
    "    hdf_suffixes = [\"02\", \"15\", \"17\"]\n",
    "\n",
    "    if not os.path.exists(output_base_folder):\n",
    "        os.makedirs(output_base_folder)\n",
    "\n",
    "    main(hdf_file_base_path, output_base_folder, hdf_suffixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87c104d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def plot_data_for_plans(base_folder, plans, data_types, name_mapping):\n",
    "    output_folder = \"plots_with_project_and_pond\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for data_type in data_types:\n",
    "        # Adjusting the data_type in the filename for \"Water Surface\" to include a space\n",
    "        adjusted_data_type = data_type.replace('_', ' ') if data_type == \"Water_Surface\" else data_type\n",
    "        \n",
    "        for name_key, friendly_name in name_mapping.items():\n",
    "            plt.figure(figsize=(10, 6), dpi=300)\n",
    "            ax = plt.gca()\n",
    "\n",
    "            for plan in plans:\n",
    "                label = \"No Pump\" if plan == 15 else \"Pump ON\"\n",
    "                # Make line style dotted for \"No Pump\"\n",
    "                line_style = \":\" if plan == 17 else \"-\"\n",
    "                \n",
    "                file_pattern = f\"{base_folder}_{plan}/{plan}_{adjusted_data_type}_{friendly_name}.csv\"\n",
    "                files = glob.glob(file_pattern)\n",
    "                if not files:\n",
    "                    print(f\"No files found for pattern: {file_pattern}\")\n",
    "                    continue\n",
    "                for file_path in files:\n",
    "                    df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "                    if not df.empty:\n",
    "                        plt.plot(df.index, df.iloc[:, 0], label=label, linestyle=line_style, linewidth=2)\n",
    "                    else:\n",
    "                        print(f\"Empty data frame for file: {file_path}\")\n",
    "\n",
    "            # Use friendly_name for the plot title\n",
    "            plt.title(f\"{friendly_name.replace('_', ' ')}: May 17, 2021 Event - With Project and Pond\", fontsize=20)\n",
    "            plt.xlabel(\"Date\", fontsize=16)\n",
    "            plt.ylabel(f\"{data_type.replace('_', ' ').title()} ({'ftÂ³/s' if data_type == 'Flow' else 'ft'})\", fontsize=16)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d %b %Y'))\n",
    "\n",
    "            ax.tick_params(axis='x', labelsize=14)\n",
    "            ax.tick_params(axis='y', labelsize=14)\n",
    "            plt.legend(fontsize=16)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plot_filename = os.path.join(output_folder, f\"{adjusted_data_type}_{friendly_name}_May_17_2021_Event.png\")\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "\n",
    "# Parameters for plotting\n",
    "base_folder = 'dataframes_output'\n",
    "plans = [15, 17]  # Include Plan 15 and Plan 17\n",
    "data_types = ['Flow', 'Water_Surface']  # Data types to plot, adjusted for correct spacing in filenames\n",
    "name_mapping = {\n",
    "    \"CryingBrewery\": \"Crying_Brewery\",\n",
    "    \"GT\": \"Greinwich_Terrace\",\n",
    "    \"Kaouche_Coulee\": \"Kayouche_Coulee\",\n",
    "    \"Near_LegionSt\": \"Near_Legion_St\",\n",
    "    \"W_Sale_Rd\": \"West_Sale_Rd\"\n",
    "}\n",
    "\n",
    "plot_data_for_plans(base_folder, plans, data_types, name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad147b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
